{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSSoCJyYC/LwyAZVmDdrpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramkumardeepak774/Text_Classification_Flair-vs-Fasttext/blob/main/text_classification_using_flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdOW4fXHZuNj",
        "outputId": "f6af2102-5a02-48c2-af81-59835f89d75a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "email_train = files.upload()\n",
        "email_test = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "-naq35zBZ8Xm",
        "outputId": "7dcbd847-abc4-492c-e610-f56ee7ef5345"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c225a933-882c-4cc3-a15d-f345eb77092d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c225a933-882c-4cc3-a15d-f345eb77092d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving idfc-email-train.csv to idfc-email-train.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40b27907-8acd-478c-ba41-e987057fe6ce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40b27907-8acd-478c-ba41-e987057fe6ce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving idfc-email-test.csv to idfc-email-test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "train = pd.read_csv(io.BytesIO(email_train[\"idfc-email-train.csv\"]))\n",
        "test = pd.read_csv(io.BytesIO(email_test[\"idfc-email-test.csv\"]))"
      ],
      "metadata": {
        "id": "Mw8cSkKdZ_Sk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns  = ['label','text']\n",
        "test.columns  = ['label','text']\n"
      ],
      "metadata": {
        "id": "tsg_ESV5aa-C"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using sklearn to shuffle rows\n",
        "from sklearn.utils import shuffle\n",
        "train = shuffle(train)\n",
        "test = shuffle(test)"
      ],
      "metadata": {
        "id": "NFJ-Lspn6MXS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Vgwp5R4gasKn",
        "outputId": "2b451be4-30a5-42ae-a911-118eb2a8613d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        label  \\\n",
              "269   Card Application Status   \n",
              "424   Card Application Status   \n",
              "534         Debit Card Offers   \n",
              "447   Card Application Status   \n",
              "1102     Matured Loan Closure   \n",
              "\n",
              "                                                   text  \n",
              "269   Required Closing Statement of Credit Card. Dea...  \n",
              "424   credit card idfc dosn't replay me for my busin...  \n",
              "534   Account Number: 10052476484 On 27th October, I...  \n",
              "447   KYC PENDING CREEDIT CARD KYC ka hamne schedule...  \n",
              "1102  Fwd: Regarding noc of loan >> ?Dear sir/Madam>...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3e3f005-5027-4ce0-949d-fafd47a4ed65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>Card Application Status</td>\n",
              "      <td>Required Closing Statement of Credit Card. Dea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>Card Application Status</td>\n",
              "      <td>credit card idfc dosn't replay me for my busin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>Debit Card Offers</td>\n",
              "      <td>Account Number: 10052476484 On 27th October, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>Card Application Status</td>\n",
              "      <td>KYC PENDING CREEDIT CARD KYC ka hamne schedule...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>Matured Loan Closure</td>\n",
              "      <td>Fwd: Regarding noc of loan &gt;&gt; ?Dear sir/Madam&gt;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3e3f005-5027-4ce0-949d-fafd47a4ed65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3e3f005-5027-4ce0-949d-fafd47a4ed65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3e3f005-5027-4ce0-949d-fafd47a4ed65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create A Folder for the csv\n",
        "!mkdir -p data"
      ],
      "metadata": {
        "id": "fi_PU3QcazEL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(\"data/train.csv\")\n",
        "test.to_csv(\"data/test.csv\")"
      ],
      "metadata": {
        "id": "Y8N6i9ZHa-KD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XDXQGFMObK-6",
        "outputId": "24821f58-9464-4962-af7e-405347d790d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.0.0+cu118)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.65.0)\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.7)\n",
            "Collecting boto3 (from flair)\n",
            "  Downloading boto3-1.26.131-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]>=4.18.0 (from flair)\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from flair) (2022.10.31)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair) (0.8.10)\n",
            "Collecting langdetect (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.2)\n",
            "Collecting ftfy (from flair)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome (from flair)\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==4.4.0 (from flair)\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub>=0.10.0 (from flair)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting conllu>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from flair) (9.1.0)\n",
            "Collecting wikipedia-api (from flair)\n",
            "  Downloading Wikipedia_API-0.5.8-py3-none-any.whl (13 kB)\n",
            "Collecting pptree (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.2.3-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (4.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.22.4)\n",
            "Collecting sentencepiece (from bpemb>=0.3.2->flair)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (6.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (16.0.3)\n",
            "Collecting datasets<3.0.0,>=2.0.0 (from transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.131 (from boto3->flair)\n",
            "  Downloading botocore-1.29.131-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->flair)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair) (0.2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.131->boto3->flair) (1.26.15)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.5.3)\n",
            "Collecting xxhash (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2022.7.1)\n",
            "Building wheels for collected packages: gdown, mpld3, sqlitedict, langdetect, pptree\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=85105b8c1bb5e0f582ec95200e2791547480fcf2f8b35c13ac407eb88f1a952f\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116685 sha256=2c5045292444643b64d9819125c3b009985c9ba9c231f3c475c4f86fc6152af5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=1aa416ae3e3d46c8a7c1cc07a69c4b49e357cdb2ef0eb4c0b37225dede9be04b\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=9dbf49e6adf5a7773ed388175c345f5fcd11724ca5f230e643442cc8d8ba4a64\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=81556182a4f4bd682ee138e59679993c6f655d54d0c31757bb24013264b44c24\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "Successfully built gdown mpld3 sqlitedict langdetect pptree\n",
            "Installing collected packages: tokenizers, sqlitedict, sentencepiece, pptree, mpld3, janome, xxhash, segtok, protobuf, multidict, langdetect, jmespath, ftfy, frozenlist, dill, deprecated, conllu, async-timeout, yarl, wikipedia-api, responses, multiprocess, huggingface-hub, botocore, aiosignal, transformers, s3transfer, gdown, bpemb, aiohttp, boto3, datasets, transformer-smaller-training-vocab, pytorch-revgrad, flair\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 boto3-1.26.131 botocore-1.29.131 bpemb-0.3.4 conllu-4.5.2 datasets-2.12.0 deprecated-1.2.13 dill-0.3.6 flair-0.12.2 frozenlist-1.3.3 ftfy-6.1.1 gdown-4.4.0 huggingface-hub-0.14.1 janome-0.4.2 jmespath-1.0.1 langdetect-1.0.9 mpld3-0.3 multidict-6.0.4 multiprocess-0.70.14 pptree-3.1 protobuf-3.20.2 pytorch-revgrad-0.2.0 responses-0.18.0 s3transfer-0.6.1 segtok-1.5.11 sentencepiece-0.1.99 sqlitedict-2.1.0 tokenizers-0.13.3 transformer-smaller-training-vocab-0.2.3 transformers-4.28.1 wikipedia-api-0.5.8 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.datasets import ClassificationCorpus,CSVClassificationCorpus\n",
        "from flair.data import Corpus"
      ],
      "metadata": {
        "id": "jnIm3TOkbCwu"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSdogp7F-njO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Column Mapping to show which column is for label and text\n",
        "column_name_map = {1:\"label\",2:\"text\"}"
      ],
      "metadata": {
        "id": "JFsXrfgrbJwZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Location for CSV\n",
        "data_folder = '/content/data'"
      ],
      "metadata": {
        "id": "gbu4jU80b391"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Corpus For CSV\n",
        "corpus_csv: Corpus = CSVClassificationCorpus(data_folder,\n",
        "                                             column_name_map=column_name_map,\n",
        "                                             skip_header=True,\n",
        "                                             label_type='label',\n",
        "                                             delimiter=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1uKV0aDcDJ2",
        "outputId": "99c9d680-57eb-4e4f-ead9-63878712d010"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:08:54,956 Reading data from /content/data\n",
            "2023-05-10 10:08:54,957 Train: /content/data/train.csv\n",
            "2023-05-10 10:08:54,959 Dev: None\n",
            "2023-05-10 10:08:54,960 Test: /content/data/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Label Diction For CSV\n",
        "label_type='label'\n",
        "label_dict_csv = corpus_csv.make_label_dictionary(label_type= label_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "940cKM4QcJoz",
        "outputId": "0519167f-8fec-4bc1-a660-476c6fc2fe48"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:09:07,786 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1296it [00:03, 360.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:09:11,388 Dictionary created for label 'label' with 7 values: Debit Card Offers (seen 225 times), Card Application Status (seen 218 times), Application Rejected (seen 216 times), Other Bank Charges (seen 215 times), Matured Loan Closure (seen 211 times), Fund Transfer (seen 211 times)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f0MP3h3cqE8",
        "outputId": "bdeec72d-da52-4a89-ada4-94fa03318ab7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=9d7c6f1ed0e92564754c81d12f9ffa0345588fe478c73ae6b73266fc31abebc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import SentenceTransformerDocumentEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "QAfPQfdjiYBM"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings=SentenceTransformerDocumentEmbeddings('bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "_JZbfY0GnN8O"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict_csv, multi_label=True, label_type=\"label\")"
      ],
      "metadata": {
        "id": "8jDtMfF8oFxB"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = ModelTrainer(classifier, corpus_csv)"
      ],
      "metadata": {
        "id": "YqjcRCA6oVNz"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train('/content/data',\n",
        "              learning_rate=0.5,\n",
        "              mini_batch_size=50,\n",
        "              max_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb4uKJk5okmN",
        "outputId": "e20abbb9-f0d8-4bdf-c9c3-b013a5835e18"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:09:42,908 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:42,910 Model: \"TextClassifier(\n",
            "  (embeddings): SentenceTransformerDocumentEmbeddings(\n",
            "    (model): SentenceTransformer(\n",
            "      (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "      (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
            "    )\n",
            "  )\n",
            "  (decoder): Linear(in_features=768, out_features=7, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            "  (locked_dropout): LockedDropout(p=0.0)\n",
            "  (word_dropout): WordDropout(p=0.0)\n",
            "  (loss_function): BCEWithLogitsLoss()\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2023-05-10 10:09:42,915 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:42,917 Corpus: \"Corpus: 1296 train + 144 dev + 360 test sentences\"\n",
            "2023-05-10 10:09:42,918 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:42,920 Parameters:\n",
            "2023-05-10 10:09:42,921  - learning_rate: \"0.500000\"\n",
            "2023-05-10 10:09:42,922  - mini_batch_size: \"50\"\n",
            "2023-05-10 10:09:42,923  - patience: \"3\"\n",
            "2023-05-10 10:09:42,925  - anneal_factor: \"0.5\"\n",
            "2023-05-10 10:09:42,926  - max_epochs: \"5\"\n",
            "2023-05-10 10:09:42,927  - shuffle: \"True\"\n",
            "2023-05-10 10:09:42,928  - train_with_dev: \"False\"\n",
            "2023-05-10 10:09:42,929  - batch_growth_annealing: \"False\"\n",
            "2023-05-10 10:09:42,929 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:42,930 Model training base path: \"/content/data\"\n",
            "2023-05-10 10:09:42,932 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:42,933 Device: cuda:0\n",
            "2023-05-10 10:09:42,934 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:42,935 Embeddings storage mode: cpu\n",
            "2023-05-10 10:09:42,936 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:09:44,654 epoch 1 - iter 2/26 - loss 5.74560440 - time (sec): 1.72 - samples/sec: 58.23 - lr: 0.500000\n",
            "2023-05-10 10:09:46,301 epoch 1 - iter 4/26 - loss 8.92189339 - time (sec): 3.36 - samples/sec: 59.45 - lr: 0.500000\n",
            "2023-05-10 10:09:47,886 epoch 1 - iter 6/26 - loss 9.71048691 - time (sec): 4.95 - samples/sec: 60.62 - lr: 0.500000\n",
            "2023-05-10 10:09:50,626 epoch 1 - iter 8/26 - loss 9.81871021 - time (sec): 7.69 - samples/sec: 52.02 - lr: 0.500000\n",
            "2023-05-10 10:09:53,303 epoch 1 - iter 10/26 - loss 9.85109286 - time (sec): 10.37 - samples/sec: 48.24 - lr: 0.500000\n",
            "2023-05-10 10:09:55,002 epoch 1 - iter 12/26 - loss 10.04301826 - time (sec): 12.07 - samples/sec: 49.73 - lr: 0.500000\n",
            "2023-05-10 10:09:56,735 epoch 1 - iter 14/26 - loss 9.95122212 - time (sec): 13.80 - samples/sec: 50.73 - lr: 0.500000\n",
            "2023-05-10 10:09:58,702 epoch 1 - iter 16/26 - loss 9.63542831 - time (sec): 15.76 - samples/sec: 50.75 - lr: 0.500000\n",
            "2023-05-10 10:10:00,810 epoch 1 - iter 18/26 - loss 9.92570875 - time (sec): 17.87 - samples/sec: 50.35 - lr: 0.500000\n",
            "2023-05-10 10:10:04,770 epoch 1 - iter 20/26 - loss 10.01068158 - time (sec): 21.83 - samples/sec: 45.80 - lr: 0.500000\n",
            "2023-05-10 10:10:07,581 epoch 1 - iter 22/26 - loss 9.96886156 - time (sec): 24.64 - samples/sec: 44.64 - lr: 0.500000\n",
            "2023-05-10 10:10:09,592 epoch 1 - iter 24/26 - loss 9.81524447 - time (sec): 26.66 - samples/sec: 45.02 - lr: 0.500000\n",
            "2023-05-10 10:10:11,187 epoch 1 - iter 26/26 - loss 9.59198090 - time (sec): 28.25 - samples/sec: 45.88 - lr: 0.500000\n",
            "2023-05-10 10:10:11,190 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:10:11,193 EPOCH 1 done: loss 9.5920 - lr 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:10:13,622 Evaluating as a multi-label problem: True\n",
            "2023-05-10 10:10:13,642 DEV : loss 14.547367095947266 - f1-score (micro avg)  0.3292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:10:13,872 BAD EPOCHS (no improvement): 0\n",
            "2023-05-10 10:10:13,873 saving best model\n",
            "2023-05-10 10:10:15,249 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:10:16,866 epoch 2 - iter 2/26 - loss 8.58165192 - time (sec): 1.62 - samples/sec: 61.90 - lr: 0.500000\n",
            "2023-05-10 10:10:18,948 epoch 2 - iter 4/26 - loss 7.65204918 - time (sec): 3.70 - samples/sec: 54.10 - lr: 0.500000\n",
            "2023-05-10 10:10:21,483 epoch 2 - iter 6/26 - loss 7.20167709 - time (sec): 6.23 - samples/sec: 48.13 - lr: 0.500000\n",
            "2023-05-10 10:10:23,861 epoch 2 - iter 8/26 - loss 7.32918949 - time (sec): 8.61 - samples/sec: 46.46 - lr: 0.500000\n",
            "2023-05-10 10:10:25,593 epoch 2 - iter 10/26 - loss 7.50335159 - time (sec): 10.34 - samples/sec: 48.34 - lr: 0.500000\n",
            "2023-05-10 10:10:27,275 epoch 2 - iter 12/26 - loss 7.56929588 - time (sec): 12.02 - samples/sec: 49.90 - lr: 0.500000\n",
            "2023-05-10 10:10:28,853 epoch 2 - iter 14/26 - loss 7.61196819 - time (sec): 13.60 - samples/sec: 51.46 - lr: 0.500000\n",
            "2023-05-10 10:10:30,631 epoch 2 - iter 16/26 - loss 7.63849840 - time (sec): 15.38 - samples/sec: 52.02 - lr: 0.500000\n",
            "2023-05-10 10:10:32,584 epoch 2 - iter 18/26 - loss 7.67171002 - time (sec): 17.33 - samples/sec: 51.92 - lr: 0.500000\n",
            "2023-05-10 10:10:34,409 epoch 2 - iter 20/26 - loss 7.54404338 - time (sec): 19.16 - samples/sec: 52.20 - lr: 0.500000\n",
            "2023-05-10 10:10:36,991 epoch 2 - iter 22/26 - loss 7.39393423 - time (sec): 21.74 - samples/sec: 50.60 - lr: 0.500000\n",
            "2023-05-10 10:10:39,205 epoch 2 - iter 24/26 - loss 7.33997150 - time (sec): 23.95 - samples/sec: 50.10 - lr: 0.500000\n",
            "2023-05-10 10:10:40,920 epoch 2 - iter 26/26 - loss 7.38092594 - time (sec): 25.67 - samples/sec: 50.49 - lr: 0.500000\n",
            "2023-05-10 10:10:40,922 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:10:40,926 EPOCH 2 done: loss 7.3809 - lr 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:10:43,410 Evaluating as a multi-label problem: True\n",
            "2023-05-10 10:10:43,430 DEV : loss 11.749005317687988 - f1-score (micro avg)  0.4444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:10:44,029 BAD EPOCHS (no improvement): 0\n",
            "2023-05-10 10:10:44,031 saving best model\n",
            "2023-05-10 10:10:45,403 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:10:47,155 epoch 3 - iter 2/26 - loss 8.24636627 - time (sec): 1.75 - samples/sec: 57.12 - lr: 0.500000\n",
            "2023-05-10 10:10:49,181 epoch 3 - iter 4/26 - loss 7.84417816 - time (sec): 3.78 - samples/sec: 52.97 - lr: 0.500000\n",
            "2023-05-10 10:10:51,731 epoch 3 - iter 6/26 - loss 7.57528147 - time (sec): 6.33 - samples/sec: 47.42 - lr: 0.500000\n",
            "2023-05-10 10:10:53,944 epoch 3 - iter 8/26 - loss 7.50846077 - time (sec): 8.54 - samples/sec: 46.84 - lr: 0.500000\n",
            "2023-05-10 10:10:55,724 epoch 3 - iter 10/26 - loss 7.45328104 - time (sec): 10.32 - samples/sec: 48.45 - lr: 0.500000\n",
            "2023-05-10 10:10:57,405 epoch 3 - iter 12/26 - loss 7.41031853 - time (sec): 12.00 - samples/sec: 50.00 - lr: 0.500000\n",
            "2023-05-10 10:10:59,042 epoch 3 - iter 14/26 - loss 7.17797078 - time (sec): 13.64 - samples/sec: 51.33 - lr: 0.500000\n",
            "2023-05-10 10:11:01,001 epoch 3 - iter 16/26 - loss 7.24287004 - time (sec): 15.60 - samples/sec: 51.29 - lr: 0.500000\n",
            "2023-05-10 10:11:02,591 epoch 3 - iter 18/26 - loss 6.97409437 - time (sec): 17.19 - samples/sec: 52.37 - lr: 0.500000\n",
            "2023-05-10 10:11:04,878 epoch 3 - iter 20/26 - loss 6.93800507 - time (sec): 19.47 - samples/sec: 51.35 - lr: 0.500000\n",
            "2023-05-10 10:11:08,060 epoch 3 - iter 22/26 - loss 7.01775841 - time (sec): 22.66 - samples/sec: 48.55 - lr: 0.500000\n",
            "2023-05-10 10:11:09,776 epoch 3 - iter 24/26 - loss 7.01038619 - time (sec): 24.37 - samples/sec: 49.24 - lr: 0.500000\n",
            "2023-05-10 10:11:11,362 epoch 3 - iter 26/26 - loss 7.02143822 - time (sec): 25.96 - samples/sec: 49.93 - lr: 0.500000\n",
            "2023-05-10 10:11:11,365 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:11:11,368 EPOCH 3 done: loss 7.0214 - lr 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:11:13,820 Evaluating as a multi-label problem: True\n",
            "2023-05-10 10:11:13,840 DEV : loss 7.99633264541626 - f1-score (micro avg)  0.4392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:11:14,429 BAD EPOCHS (no improvement): 1\n",
            "2023-05-10 10:11:14,430 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:11:16,086 epoch 4 - iter 2/26 - loss 5.39852341 - time (sec): 1.65 - samples/sec: 60.49 - lr: 0.500000\n",
            "2023-05-10 10:11:17,729 epoch 4 - iter 4/26 - loss 6.44460373 - time (sec): 3.30 - samples/sec: 60.68 - lr: 0.500000\n",
            "2023-05-10 10:11:20,041 epoch 4 - iter 6/26 - loss 6.15822891 - time (sec): 5.61 - samples/sec: 53.49 - lr: 0.500000\n",
            "2023-05-10 10:11:22,736 epoch 4 - iter 8/26 - loss 6.28386875 - time (sec): 8.30 - samples/sec: 48.18 - lr: 0.500000\n",
            "2023-05-10 10:11:24,449 epoch 4 - iter 10/26 - loss 6.14559305 - time (sec): 10.02 - samples/sec: 49.92 - lr: 0.500000\n",
            "2023-05-10 10:11:26,093 epoch 4 - iter 12/26 - loss 5.85799309 - time (sec): 11.66 - samples/sec: 51.46 - lr: 0.500000\n",
            "2023-05-10 10:11:28,193 epoch 4 - iter 14/26 - loss 5.85061334 - time (sec): 13.76 - samples/sec: 50.87 - lr: 0.500000\n",
            "2023-05-10 10:11:29,945 epoch 4 - iter 16/26 - loss 5.81238668 - time (sec): 15.51 - samples/sec: 51.57 - lr: 0.500000\n",
            "2023-05-10 10:11:31,749 epoch 4 - iter 18/26 - loss 6.00910161 - time (sec): 17.32 - samples/sec: 51.98 - lr: 0.500000\n",
            "2023-05-10 10:11:33,795 epoch 4 - iter 20/26 - loss 6.15043814 - time (sec): 19.36 - samples/sec: 51.65 - lr: 0.500000\n",
            "2023-05-10 10:11:36,560 epoch 4 - iter 22/26 - loss 6.22096255 - time (sec): 22.13 - samples/sec: 49.71 - lr: 0.500000\n",
            "2023-05-10 10:11:38,771 epoch 4 - iter 24/26 - loss 6.30707982 - time (sec): 24.34 - samples/sec: 49.31 - lr: 0.500000\n",
            "2023-05-10 10:11:40,525 epoch 4 - iter 26/26 - loss 6.33733539 - time (sec): 26.09 - samples/sec: 49.67 - lr: 0.500000\n",
            "2023-05-10 10:11:40,528 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:11:40,531 EPOCH 4 done: loss 6.3373 - lr 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:11:43,410 Evaluating as a multi-label problem: True\n",
            "2023-05-10 10:11:43,431 DEV : loss 14.232457160949707 - f1-score (micro avg)  0.4808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:11:43,687 BAD EPOCHS (no improvement): 0\n",
            "2023-05-10 10:11:43,688 saving best model\n",
            "2023-05-10 10:11:45,068 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:11:46,853 epoch 5 - iter 2/26 - loss 9.34966301 - time (sec): 1.78 - samples/sec: 56.10 - lr: 0.500000\n",
            "2023-05-10 10:11:48,640 epoch 5 - iter 4/26 - loss 8.46191525 - time (sec): 3.57 - samples/sec: 56.04 - lr: 0.500000\n",
            "2023-05-10 10:11:51,544 epoch 5 - iter 6/26 - loss 7.74266284 - time (sec): 6.47 - samples/sec: 46.35 - lr: 0.500000\n",
            "2023-05-10 10:11:53,873 epoch 5 - iter 8/26 - loss 7.70527517 - time (sec): 8.80 - samples/sec: 45.44 - lr: 0.500000\n",
            "2023-05-10 10:11:55,967 epoch 5 - iter 10/26 - loss 7.48586803 - time (sec): 10.90 - samples/sec: 45.89 - lr: 0.500000\n",
            "2023-05-10 10:11:57,638 epoch 5 - iter 12/26 - loss 7.38251759 - time (sec): 12.57 - samples/sec: 47.74 - lr: 0.500000\n",
            "2023-05-10 10:11:59,241 epoch 5 - iter 14/26 - loss 7.13020335 - time (sec): 14.17 - samples/sec: 49.40 - lr: 0.500000\n",
            "2023-05-10 10:12:00,899 epoch 5 - iter 16/26 - loss 7.19028916 - time (sec): 15.83 - samples/sec: 50.54 - lr: 0.500000\n",
            "2023-05-10 10:12:02,552 epoch 5 - iter 18/26 - loss 7.12738655 - time (sec): 17.48 - samples/sec: 51.48 - lr: 0.500000\n",
            "2023-05-10 10:12:04,701 epoch 5 - iter 20/26 - loss 7.04729617 - time (sec): 19.63 - samples/sec: 50.94 - lr: 0.500000\n",
            "2023-05-10 10:12:07,585 epoch 5 - iter 22/26 - loss 6.94886216 - time (sec): 22.51 - samples/sec: 48.86 - lr: 0.500000\n",
            "2023-05-10 10:12:09,974 epoch 5 - iter 24/26 - loss 6.82340774 - time (sec): 24.90 - samples/sec: 48.19 - lr: 0.500000\n",
            "2023-05-10 10:12:11,522 epoch 5 - iter 26/26 - loss 6.70834138 - time (sec): 26.45 - samples/sec: 48.99 - lr: 0.500000\n",
            "2023-05-10 10:12:11,526 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-10 10:12:11,528 EPOCH 5 done: loss 6.7083 - lr 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:12:14,040 Evaluating as a multi-label problem: True\n",
            "2023-05-10 10:12:14,059 DEV : loss 5.957902431488037 - f1-score (micro avg)  0.5723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:12:14,294 BAD EPOCHS (no improvement): 0\n",
            "2023-05-10 10:12:14,295 saving best model\n",
            "2023-05-10 10:12:17,454 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:12:27,399 Evaluating as a multi-label problem: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-10 10:12:27,423 0.5035\t0.6056\t0.5498\t0.4083\n",
            "2023-05-10 10:12:27,424 \n",
            "Results:\n",
            "- F-score (micro) 0.5498\n",
            "- F-score (macro) 0.5133\n",
            "- Accuracy 0.4083\n",
            "\n",
            "By class:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "   Application Rejected     0.3455    0.9500    0.5067        60\n",
            "          Fund Transfer     0.3852    0.7833    0.5165        60\n",
            "     Other Bank Charges     0.6324    0.7167    0.6719        60\n",
            "   Matured Loan Closure     0.9245    0.8167    0.8673        60\n",
            "      Debit Card Offers     0.8800    0.3667    0.5176        60\n",
            "Card Application Status     0.0000    0.0000    0.0000        60\n",
            "\n",
            "              micro avg     0.5035    0.6056    0.5498       360\n",
            "              macro avg     0.5279    0.6056    0.5133       360\n",
            "           weighted avg     0.5279    0.6056    0.5133       360\n",
            "            samples avg     0.5056    0.6056    0.5384       360\n",
            "\n",
            "2023-05-10 10:12:27,426 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.5498108448928122,\n",
              " 'dev_score_history': [0.3292181069958848,\n",
              "  0.4444444444444445,\n",
              "  0.4392156862745098,\n",
              "  0.48081841432225064,\n",
              "  0.5723270440251572],\n",
              " 'train_loss_history': [9.591980898821795,\n",
              "  7.380925943822037,\n",
              "  7.021438221872589,\n",
              "  6.337335386393983,\n",
              "  6.708341380696238],\n",
              " 'dev_loss_history': [14.547367095947266,\n",
              "  11.749005317687988,\n",
              "  7.99633264541626,\n",
              "  14.232457160949707,\n",
              "  5.957902431488037]}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBFCjhAUJji2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text classfication on sysco data "
      ],
      "metadata": {
        "id": "SvoEbdABEZ23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "sysco = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "EsthcusREYQf",
        "outputId": "f27719f3-4a85-4a47-c47f-7e12f05dd7a6"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b98aee84-8c97-4c1b-ac95-e39ce171deda\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b98aee84-8c97-4c1b-ac95-e39ce171deda\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sysco-full.csv to sysco-full.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sysco.head()"
      ],
      "metadata": {
        "id": "2v3ZEJZ3I48_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}